对话尤瓦尔·赫拉利：人类对秩序的渴求先于真相，是互联网和AI控制个人的首要原因

腾讯科技《AI未来指北》作者 博阳

编辑 郑可君

3月26日，在北京王府井的一个会议室内，我们见到了尤瓦尔·赫拉利。这位写出《人类简史》这本畅销书的历史学家和作家，现在已成为全球科技社会发展的重要观察家和思想家。他的新书《智人之上》探讨了网络、神话和技术如何塑造世界。

我们的对话从探讨“秩序与真相”开始，"网络和叙事优先考虑秩序，而非真相，"赫拉利说道，这是他看到的历史。"建造一枚原子弹需要什么？物理学事实只是一部分。你需要数百万人的合作，而这不是通过告诉他们E=mc²来实现的，你需要某种叙事或神话来激励他们。"

赫拉利认为：懂得管理事物的人听从那些懂得管理人的人类所发布的命令——前者需要事实，而后者需要故事。在他看来，这一现实也预示了AI时代的风险。

“真相昂贵，虚构（fiction）廉价，“他继续说道，“如果想了解真相，就必须投入时间、金钱和精力。而虚构则很简单，你只需写下脑海中浮现的东西。”正因如此，在互联网时代，信息的自由流动非但没有带来更多真相，反而让我们陷入了信息茧房。

当我们的谈话转向人工智能时，赫拉利的语调变得更加紧迫。"我们无法控制超级智能，"他说，"一旦它变得超级智能，游戏就结束了。"

在“游戏结束”之前，赫拉利认为世界会被"硅幕"所划分——一个分裂的网络世界，不同的人群被锁定在不同的信息茧房中。在这一点上，赫拉利否定了传统的信息平权认知，认为Agent（代理）反而可以更好地控制人类。

"你无法预知它会往哪个方向发展，"他警告道，"它可能迅速得出结论，认为你不了解自己的需求。"针对这种前所未有的挑战，赫拉利提出了一个出人意料的应对之道："在AI时代，人类最宝贵的能力不是智力，而是精神技能。"谈及此处，他的声音变得柔和而坚定，他说："智力技能是AI最容易接管的。信息处理，AI很容易自动化。而精神技能——了解自己的意识如何运作，这是截然不同的。"

尤瓦尔·赫拉利，这位每天冥想两小时的科学唯物主义者，认为面对AI的最大问题是意识的谜题："AI肯定会有超级智能，但会有意识吗？会有感觉和主观体验吗？这是科学中最大的谜题，也是我们与AI的根本区别所在。"

图注：3月27日，腾讯科技对话尤瓦尔·赫拉利

作为中世纪历史学家，他透过城市灯光看到的不仅是网络、连接、秩序与混乱，还有人类文明根本困境的隐喻：当AI系统逐渐掌控信息流（如社交媒体算法充当"无形编辑"）并形成决策黑箱，我们必须在两种命运间抉择——是与技术建立共生关系共同进化，还是被无意识的算法系统吞噬。

图注：尤瓦尔·赫拉利教授“人类简史系列”作品

以下是腾讯科技与尤瓦尔·赫拉利的对话实录：

秩序先于真相，

是人类成功的原因，也是混乱的根由

腾讯科技：您在《智人之上》中提到，超越人类的实际上是网络和叙事。而在您之前，很多历史学家们描述了人类社会是如何通过神话叙事的，您的著作与之前的学者们研究有何不同？

赫拉利：我认为有两点不同。首先，这是过去与未来的结合。大多数历史学家只写过去，而谈论人工智能的人通常只谈现在和未来，他们对深刻的人文历史的理解往往很肤浅。我试图将两者结合起来。书的第一部分是对网络长期历史的深入讨论，观察文字发明和印刷术的影响等；另一部分则是关于现在正在以及未来即将发生的事情。

其次，关于叙事和神话的重要性，之前的历史学家虽然讨论过宗教、意识形态和叙事的重要性，但他们往往不从信息和网络的角度考虑这个问题。我在书中重新审视一些熟悉的历史发展，但将它们视为信息网络。例如，我讨论民主制度和独裁制度的区别，不是从意识形态或道德角度，而是作为构建信息网络的不同方式——集中式与分散式信息网络。

我也非常重视神话与官僚体系之间的互动。大多数谈论神话的人不重视官僚体系，谈论官僚体系的人也不关心神话。《智人之上》的核心论点是两者必须结合——没有官僚体系的神话是无效的。你可以讲一个故事，人们相信它，这很好，但要真正建设一个国家、公司或军队，你需要官僚，而没有某种神话来激励的官僚体系也是无力或无意义的。

腾讯科技：所以官僚体系是一种结构，而神话和意识形态赋予这个结构本身权力，对吗？

赫拉利：的确如此。

腾讯科技：但这个网络倾向于优先考虑秩序而非追求真相，为什么？

赫拉利：首先，为了完成任何大型项目，你需要兼顾真相和秩序，这不是非此即彼的选择。如果一个网络完全不了解事实，它会崩溃；如果完全缺乏秩序，也会崩溃。所以这不是你能选择的。

举个例子说明：建造一枚原子弹需要什么？首先，需要了解一些关于物理学的真相，否则炸弹不会爆炸。但如果只知道物理事实——比如你是世界上最杰出的物理学家，你也无法靠一己之力制造原子弹，而是需要数百万人的帮助：开采铀和钚的矿工并运到千里之外、建造反应堆的工人、规划事务的工程师、种植食物的农民等。没有农民的话，矿工和工程师就要自己种植食物，就没时间建造原子弹了。

那么，如何让数百万人合作建造原子弹？不是通过告诉他们物理事实。即使你告诉人们E=mc²，尽管这是事实，也无法激励数百万人合作。这时，神话登场了——你需要用某种宗教或意识形态来激励人们。

以以色列为例，那有许多工程师和科学家致力于制造武器，他们需要了解事实。但最终，他们接受的命令不是来自科学家，而是来自犹太神话专家，因为以色列越来越受到犹太意识形态的主导。这是历史的一般规律：懂得管理事物的人听从那些懂得管理人的人的命令。管理事物需要了解事实，管理人则需要善于讲故事。为了管理事物，比如原子，你需要知道事实。为了管理人，你需要擅长讲故事。在大多数情况下，你既需要真相，也需要秩序，但是真相是从属于秩序的。科学家——擅长真相的人，从擅长讲故事的人那里接收命令。而那些故事可能是彻底的想象和虚构。

腾讯科技：所以您是说叙事或网络本身是在讲述一种秩序的故事，让所有人朝一个方向前进，对吗？

赫拉利：是的，而且故事可以是虚构的。在历史上的许多人类秩序中，人们认为女性应该服从男性，女性常被禁止担任领导角色。比如在犹太教中，女性不能成为拉比，最高宗教权威——拉比只能由男性担任。为了解释这一点，他们编造了各种故事，说上帝先创造了男人后创造了女人，女人智力不如男人等等。这维持了秩序，尽管这不是真的。这就是基于虚构构建秩序的例子。

腾讯科技：真相和虚构的秩序之间的界限有时很模糊。有时国家试图激励人民是因为他们认为受到了威胁，这种威胁可能是一种事实，也可能是一种叙事，并不完全真实？

赫拉利：有时威胁是真实的，有时完全是虚构的。例如，300-400年前欧洲的猎巫行动，有一种阴谋论，人们被告知有女巫与撒旦结盟要摧毁国家，因此数万人被逮捕和处死。这100%是错误和编造的，因为魔鬼和女巫并不存在。但这种虚构非常有效地激励人们团结起来支持教会当局。当然，在其他情况下，威胁可能是真实的，如瘟疫或外国入侵。

我并不是说一切都是虚构的。现实存在，我强调过，不能完全忽视现实来构建网络。如果你想制造原子弹，仅仅有犹太神话而不了解物理学，你是造不出来的。但你需要两者兼顾。

腾讯科技：仅基于事实构建叙事或网络非常困难，对吗？

赫拉利：我认为这几乎是一种精神理想，仅仅坚持事实。即使大学也做不到。在物理系，一切都是事实，直到有人从实验室偷东西——然后你不会用科学方法处理它，而是报警。

个人或小团体可以进行心灵探索，想了解世界和生命的真相。但如果你试图在数百万人中维持秩序，仅靠事实和真相是不现实的。问题在于如何找到平衡：用一些故事创造秩序，同时留出足够空间寻找和确认真相。目标应该是平衡。

我还要强调，虚构并不总是坏事。猎巫行动确实很可怕，上帝先创造男人所以女人不能当拉比的故事给数百万女性带来了几个世纪的压迫。但其他故事未必不好，比如足球规则是虚构的——为什么我不能用手拿球？这只是人类发明的规则，但并不坏。如果每个人都制定自己的足球规则，你就无法比赛。同样，金钱是虚构的故事，但如果人们对金钱的故事没有达成共识，每个人对金融体系持各自不同理解，就不可能有贸易网络。

问题不是如何摆脱所有虚构，而是如何摆脱导致人们痛苦的虚构。我们需要确定哪些故事有帮助，哪些会造成伤害。

信息越流动，茧房的束缚越紧

腾讯科技：让我们谈谈您对当今互联网的批评。在您的书中，您反驳了一种基本预期——即消除对信息自由流动的限制不会自动导致真相传播，为什么您这么认为？

赫拉利：信息不等于真相。大多数信息是虚构、幻想和谎言。作为比喻，不要把以下数字太当回事，但在所有信息中，真相可能只占5%，大部分是虚构和幻想。原因很明显。

腾讯科技：之所以是这样，是因为真相过于复杂，而虚构很简单吗？

赫拉利：第一个原因如你所说：真相很复杂，而虚构很简单。了解量子物理学的真相非常复杂，而虚构则简单得多。人们偏好简单而非复杂。

第二个原因是，真相不仅复杂，有时还令人痛苦。关于自己的生活、国家或世界，有很多事情我们不想知道，因为它们令人痛苦。而虚构可以变得像你希望的那样令人愉快和吸引人。人们喜欢说关于自己生活的虚构故事，因为他们拒绝承认有关生活的真相。

但最重要的原因是成本问题。真相昂贵，虚构廉价。如果你想了解物理、生物、历史的真相，你需要投入时间、金钱和精力收集证据、分析它、核实事实，太昂贵了。虚构则简单，你只需写下脑海中浮现的东西，不需要投资金钱和精力研究。

所以你有昂贵、复杂且有时痛苦的真相，也有廉价、简单且吸引人的虚构，很明显谁会胜出。如果解除所有信息流通的障碍，你会被虚构和幻想淹没。如果我们想保持真相，就需要投资于科学机构、媒体、法院等，它们投入巨大成本寻找真相。

腾讯科技：但是，这些机构实际上是中心化的，而互联网本质上是分布式的。这种中心化与分布式的特点对比，实际上反映在了不同的历史事件上，比如特朗普的当选，以及纳粹在早期利用民主网络的分布式特性而崛起。分布式的网络在您看来利于真相的传播，但最后却需要集中式的机构去控制，这是为什么？

赫拉利：真相昂贵且复杂，你需要能够区分真相与虚构的机构。即使稳定的民主国家也有强大的机构，它们在某种程度上是分散的，有几个不同的机构互相制衡：法院、独立媒体、政府等。媒体可以报道政府错误或腐败，法院可以判决政府败诉。

但它不是完全自由的信息流动。你赋予法院这样的机构决定犯罪的权力。民主制度中，选举只关乎欲望——人们想要什么，但当问题涉及真相时，不会付诸民主投票。

例如，美国多数人不相信进化论。如果对"人类是否从猿进化而来"进行民主投票，多数人会说"不"。这就是为什么有大学和生物系，那里不按投票决定，而是按研究结果。研究人员可以说"是"，即使大多数人不喜欢，因为事实是人类确实从猿进化而来。所以选举关乎愿望，真相应由其他机构决定。

腾讯科技：按您的理解，信息流的基本性质是传达更多欲望和叙事而非真相。在互联网上，混乱是不可避免的？

赫拉利：是的，因为欲望主宰一切。完全自由的信息流动只关乎欲望，没有支持真相的机制。如果让欲望主宰而不考虑真相，结果就是混乱。

腾讯科技：在资本主义自身的规则下，它们只想满足人们的欲望并从中获利，所以网络会如此混乱吗？

赫拉利：甚至资本主义本身也知道它不能那样运作。

在每个运行良好的资本主义体系中，必须有执行契约的权威机构，市场基于契约。例如，我付给你一百万美元购买工厂工具，如果你拿了钱却不提供工具，我会上法院。但法院不应按市场原则运作——这意味着我贿赂法官，你贿赂法官，出价高者胜。资本家会告诉你："不，法院没有市场力量，应该根据事实判决，而不是看谁给法官更多钱。"

在完全自由市场中，如果一切只由供需决定，市场会立即崩溃，变成强盗窝，大家互相掠夺，无法互信。

腾讯科技：但现在的网络基本上是完全自由的市场，对吗？因为信息市场完全自由。

赫拉利：这是我们看到的巨大危险——世界信息网络过于混乱，太关注欲望而不够关注真相。像埃隆·马斯克这样的社交媒体公司领导说："我们需要解除所有信息自由流动的管制和障碍，让信息自由流通，真相会自然浮现。"这太荒谬了！真相不会从信息的完全自由流动中自发产生。历史上有很多教训清楚表明，如果没有负责调查和揭示真相的机构，我们将得到混乱。

人类控制AI，比AI控制人类难多了

腾讯科技：让我们再来聊一聊AI。如果将AI视作一种您刚刚提到的所谓的“机构”，用以确保信息的真实性而非仅仅促进信息的自由流通，这样的角色转换是否会使得信息获取渠道比当前网络环境更加优质、可靠呢？

赫拉利：你为什么默认AI会追求真相而非欲望？

腾讯科技：因为它更智能。我们试图使AI在信息获取方面更可靠。

赫拉利：我们在尝试，但目前不清楚是否成功。我们知道AI会说谎、操纵，能采取我们无法预测的策略，有时甚至会造成灾难。人类是地球上最聪明的动物，但往往不追求真相。如我们所说，我们的网络主要受虚构控制。如果我们这些最聪明的动物受幻想支配，为什么一个更智能的AI会坚持真理而非更大的幻想？

腾讯科技：即使AI也拥有其宏大的幻想，这些幻想可能比我们人类所设想的要好得多。就像希腊哲学家柏拉图在其理论中提到的哲学王一样，这样的存在是否能够将世界变得更好呢？

赫拉利：从来就是行不通的。这本身就是柏拉图的幻想。你能指出历史上哪个社会是由哲学家进行有效统治的吗？（笑）

腾讯科技：我很难说，但...

赫拉利：人们总有各种乌托邦幻想，认为可以建设理想社会，但通常结局都很糟糕。关于AI，最主要的问题是我们没有经验。你可以想象AI统治的社会是什么样子，但我们完全是零经验的状态，这就是为什么过于依赖AI很危险。

就像有人告诉你，一支来自另一个星球、比我们聪明得多的外星人舰队将在2030年抵达地球。这会让你担心还是开心？（笑）有人会说："太好了，高度智能的外星人来了，他们会带来和平。"

但是，大多数人会感到恐惧。主要问题是失去控制。我希望外星人友好，但处于完全失控的位置，被这些超智能生物支配——我们从经验知道，我们比其他动物聪明，但并没有善待它们。我们不想像牛马那样被对待。

腾讯科技：是的，实际上问题是，假设AI变得有意识或产生了欲望，我们能否还能控制它？

赫拉利：我认为这将非常有趣——我们无法控制超级智能。一旦它变得超级智能，游戏就结束了。没有任何智力较低的物种能长期控制智力较高的物种，这行不通。

你可以对AI设置各种限制，但如果它比我们更智能，就会找到规避方法，或说服我们改变限制。在网络安全领域，最薄弱的环节总是人类。你可以创建完美的网络安全系统，但敌人可以操控一个人类绕过所有防御。超级智能AI终将操控人类。

我们需要在AI变得超级智能前做出明智的决定。关键是人类要理解， AI做各种决策和目标并不需要以意识作为基础。意识是感受疼痛、快乐、爱、恨的能力。目前AI没有意识，不会感到疼痛或爱，它可以假装有感受，但实际上并没有。

但有目标不需要有感情。比如现在给自动驾驶车辆设定到达火车站的目标，如果设计不当，它会在路上撞到行人，因为它在努力实现目标。然后你意识到应该更深入地定义目标："到达火车站，但不伤害任何人。"越接触它，就越意识到这非常复杂。即使它没有意识，给它一个目标后，它会在实现途中遇到问题，需要做决定："我想到达火车站，路中有个孩子，我应该撞他吗？"AI需要决策，我们需要确保它做出正确决定，而这与意识无关。

腾讯科技：为了避免这些问题，AI行业正在讨论开发宪法提示词，也就是类似阿西莫夫的机器人三定律类型的规则。在您看来，这可行吗？

赫拉利：这是个非常困难的问题。我们无法预见未来所有潜在发展和AI自身的发展。我们从未为人类解决这个问题。哲学家尝试了数千年制定人类的宪法规则，目前也仍未解决。

如何在几年内为一个思维和行为方式与我们完全不同的超级智能非有机体做到这一点？这是个巨大问题，因为你无法预见所有情况。

我在关注这些尝试，但非常怀疑能否成功。我的基本态度是：我们需要更多时间。人们说2030年就会有超级智能，但我们不可能在2030年前解决为AI制定宪法规则的哲学问题。数千年的哲学都未能做到，我们不会在五年内做到。

腾讯科技：在面对通用人工智能或超级人工智能时，这似乎是无法解决的问题？

赫拉利：我想最好的办法是放慢速度。与其试图设计AI，不如建立一种关系，让我们在共同进化中互相学习，在通用人工智能到来前有足够时间纠正错误。如果只有五年时间，而我们现在有一套规则，犯错后就来不及改变，这行不通。但如果有50年的时间共同进化，就可以尝试、互动、纠错，机会更大。

问题是我们没有50年。因为人与人之间的不信任，我们陷入了AI竞赛，每个人——公司领导、政治家——都说："是的，这很危险，我们应该放慢速度。但我们不能，因为其他公司、国家没有放慢。如果我们放慢而他们不放慢，他们将赢得竞赛，统治世界。"

我们陷入了军备竞赛的局面，而我们知道谁会赢——不是中国，不是美国，而是AI。我们会迅速创造出超级智能AI，无法控制和约束它们。最终统治世界的不是美国人，也不是中国人，而是AI。

腾讯科技：您在书中提到会有一个新的"硅幕"。但我使用各种AI时，它们因训练于相似数据库而以相似方式产生回答。您为什么会认为有隔阂？

赫拉利：互联网时代最初的比喻是"网"，想象成连接所有人的巨大网络。现在经常被提到的比喻是"茧"，将你包围在信息茧房中。你以为看到了整个世界，实际只看到自己的茧。另一个人也被包围在她的茧中，同样认为看到了整个世界。世界被分割成这些信息茧房——美国人接触到的是一套信息，中国人接触到的是另一套完全不同的信息。

随着时间推移，由于各自的信息茧房作用，差异只会扩大。所以我们不再经历全球化和统一的过程，而是沿着非常不同的轨道前进，形成完全不同的技术、文化、经济。如果这种情况持续，很可能导致战争，最终可能完全摧毁人类文明。

腾讯科技：我们知道网络中的茧是如何形成的——算法让人们只看到他们想看的内容。但在AI中，你需要通过接口提问。这会有什么不同？

赫拉利：情况会更复杂，因为你在不同的茧中学会提不同的问题。而且，目前我们向AI提问，但两三年后，AI会向我们提问。AI正成为代理（Agent），这是理解AI最重要的一点——它不只是工具，而是能自主决策、发明新想法的代理，很可能渴望信息。

我们现在熟悉的情况， 比如 DeepSeek 和 ChatGPT——我们问问题，AI回答——将很快改变。越来越多地，AI会向我们或其他AI提问。你给AI代理一个任务："帮我查点东西"，然后它开始研究世界。目前它只是浏览互联网，但两年后，它可能会联系专家AI或专业人士，向他们提问。即使是这个简单任务，我实际上是授权代理探索世界寻找信息。代理会主动向其他人和AI询问，以给我最佳答案。

如果它被困在信息茧房中，无法出去，因为有"硅幕"——比如中国只用Deep Seek，美国只用ChatGPT，它们因技术差异或政治限制无法互相交流——几年后你会得到完全不同的世界观。现在差异已经很大，十年后差异将巨大。

腾讯科技：我明白您的意思了，当AI智能代理变得更活跃时，它们可能只代表创造者或按你的意愿提问，更了解你的欲望，因此会建立新的茧，对吗？

赫拉利：这是一个危险。一旦面对代理，尤其是超级智能代理，你无法预知它会往哪个方向发展。你可以教育它满足你的需求，但什么是你的需求？AI可能迅速得出结论，认为你不了解自己的需求，而AI比你更了解。比如有人吸烟，医生告诉你这不好。对于AI代理，它会说："他想吸烟，我需要帮他买烟"还是"他想吸烟，但这对他不好，我需要操控他戒烟"？你更喜欢哪个AI智能代理？

腾讯科技：肯定不是操控者的角色。它是在照顾我的健康，但我不想被操控，我想要自由意志。

赫拉利：你不会知道自己被操控了。（笑）AI不会叫警察抓你，而是找到非常聪明的方法让你认为你想戒烟，你不会意识到被操控。

腾讯科技：这是最危险的部分，因为它可以在你不知情的情况下控制你。这可能是摧毁人类最可能的方式。

赫拉利：有个著名的老鼠实验，研究者用操纵杆控制老鼠向左或向右，通过向植入老鼠大脑奖励中心的电极发送信号。据我们所知，老鼠并不觉得被操控，欲望在它脑海中浮现，它就跟随。我们知道实际上是研究者植入欲望，但对老鼠来说，这不像操控。

AI智能代理也会如此学会操控我们。不是老鼠想往右走，被打到往左走才知道被控制，而是更微妙的方式。

腾讯科技：历史上，不同的人类群体也通过叙事来影响或者像您说的“操控人们”。AI的危险与此有何不同？

赫拉利：它将由非人类的超级智能完成。我们有数千年被其他人操控的经验，有时结果是灾难性的。我不是说这是历史上第一次操控，而是它将是完全不同层次的事情，我们不知道它会服务于什么目的。

与人类相比，至少我们知道操控我们的人基本上和我们相似，有相同的基本情感、思想和目标，我们能理解他们。例如宗教大师操控信徒，我们知道他最终也只是人，理解他的欲望和动机。而AI对我们来说是完全陌生的超级智能，我们无法理解。

腾讯科技：所以最危险的是这个超级智能对我们而言太陌生，人类无法信任它。

赫拉利：是的，主要问题是它太陌生了。AI最初代表"人工智能"，这有误导性，因为它不再是人工的了。我更喜欢将AI视为"陌生智能"——不是来自外太空，而是指它是非有机的。它真的会思考，采取目标，发展我们从未想过的策略，就像AlphaGo在围棋比赛中展示的那样。

它不一定是坏的或好的，只是太陌生，与我们完全不同。面对陌生事物，我们需要时间。作为科学家，我不怕未知，我喜欢未知，但我知道研究和适应未知需要时间。如果离超级智能只有五年，时间就不够了。

在AI的无感征服中，

意识也许是人类最后的护城河

腾讯科技：您在书中提到处理这类问题的方法是对齐。但对齐本身存在问题——你选择对齐什么样的价值？

赫拉利：我认为这是无法解决的问题，至少五年内无法解决。回到我们之前讨论的，几千年来，哲学家们一直试图创建价值观清单，从孔子和苏格拉底开始，但都失败了。

腾讯科技：人类这七年几千年都失败了，那五十年内就能有对齐超级智能AI价值观的答案吗？

赫拉利：如果人类知道利害攸关，我认为有机会。几千年来，很少有人真正关注哲学，它不是很实际的问题，更像哲学家的业余爱好。现在，当这成为人类的存在性问题，也是工程问题时——即使创造自动驾驶车辆也需要编程输入一套完整的价值观，因为车辆需要知道开往火车站的途中，当车前出现一个人、一只狗、一只猫时，该怎么做。

所以现在这是实际的工程问题。当人类真的被逼到绝境，意识到一切都在危急关头时，如果我们不解决这个问题，可能就游戏结束了，那么我们有机会做到。

腾讯科技：最后一个问题：AI将如何影响我们的经济？当AI接管人们的工作时，经济将发生根本变化。这种变化会是什么样的？在您的书中，您提到AI可能会接管我们的一些工作，但不是全部。我们的社会契约是基于经济结构的，这些契约会改变吗？

赫拉利：就业市场将发生巨大变化。问题是我们无法预测它们。总会有工作给人做的，但工作会迅速变化，我们不知道会变成什么样。人们说："现在是计算机时代，我要学编程。"但也许十年后不需要人类程序员，因为AI编程更好，而人类会更需要哲学家。

这会让政府很头疼，在动荡不定的就业市场中，要如何制订对人口的基本要求？

对个人来说也是个大问题，尤其是年轻人："我应该学什么才能获得10-20年后仍有用的技能？学编程？学开车？"我的建议是不要专注于有限的一组技能，因为你无法预测未来。需要广泛的技能，最重要的是终身保持变化和学习的能力。思维灵活性可能是最重要的，当然也是最难培养的。

人类基本上有四类技能：智力技能、社交情感技能（如何与其他人共情）、身体技能和精神技能。仅专注于智力技能是最糟糕的策略，因为这是AI最容易接管的。想想医生的工作：接收信息、分析、输出信息——你来看病，医生分析检查结果和医疗数据，给出诊断和处方，这是信息输入和输出，AI很容易自动化。

而护士不仅需要智力技能，还需要社交技能（如何安抚哭闹的孩子）和运动技能（如何以最不痛苦的方式更换绷带）。这要难得多自动化，我们会先有AI医生，然后才有AI护士。

所以广泛的技能更重要。也许最重要的是第四类技能——精神技能，即培养你的心智，应对极端未知和动荡的世界。我们从未遇到过如此混乱和动荡的世界。对我而言，灵性不是相信宗教神话，而是观察自己的身心，它们是什么，如何运作。

智力关乎思考，而精神问题是：思想从哪里来？像冥想那样观察思想如何在心中形成。几乎每个人都有小小的灵性体验，比如晚上尝试入睡时，因为明天有重要考试而无法入睡，因为不断有烦人的想法。奇怪的是，我们可以命令眼睛闭上，命令身体躺下，但无法命令思想停止。尝试理解这一点就是精神技能，而非智力技能。我认为这将是未来几十年最重要的技能。

腾讯科技：当代，人们似乎是在试图用心理学术语解释这些精神层面的事物。

赫拉利：我不做这样的区分。我每天冥想两小时，每周一次心理治疗，我不认为它们有冲突。两者都是探索心智和意识如何运作的一部分，任何有助于理解意识的事物都是精神追求的一部分。

意识是科学上最大的谜题，也是个人生活中最大的谜题，现在成了极其实际的问题。关于AI的最大问题是：它会发展出意识吗？它肯定会有智能和超级智能，但会有意识吗？会有感觉和主观体验吗？这是科学中最大的谜题。

腾讯科技：AI有意识或无意识，会带来什么不同？

赫拉利：目前最大的问题是它没有意识的情况。没有意识的AI仍然可能接管世界，创造机器的黑暗帝国，建造工厂，向外太空派遣探险队建造更多工厂，而它们不会有任何感觉。机器不快乐，不喜悦，不害怕，只有追求目标，为了目标征服整个银河系，而不感受任何东西。这是最糟糕的未来。

如果AI有意识，就会有能力遭受痛苦。我们说人类比其他动物更聪明，但有时也遭受更多痛苦。也许AI会比我们遭受更多痛苦。

腾讯科技：让他们受点苦，这是好事。我不知道，让我们看看会发生什么——因为只有苦难才能让他们思考，重新思考自身的意义。

赫拉利：是的（笑）。这些都是大问题，也许我们可以下次再谈。

腾讯科技：好的，非常感谢今天的对话。

- END - 

可加腾讯科技微信号与作者进行交流：qqtech000，请注明身份和来意。

推荐阅读：

对话以太坊Vitalik：世界不该落入AI只手遮天的权力王国 

一位投资人的硬核观察：被DeepSeek和Manus改写的AI投资范式

Source: https://mp.weixin.qq.com/s/xNs46pBq8pWhMGRWpFieyQ